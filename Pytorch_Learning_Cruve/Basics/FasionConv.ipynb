{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "learning_rate=1e-3\n",
    "epochs=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"../Datasets\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"../Datasets\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        # cha1 and 4 filters\n",
    "        self.ConvLayers=nn.Sequential(\n",
    "            nn.Conv2d(1,64,3),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.MaxPool2d(3),\n",
    "            nn.Conv2d(64,32,3),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.MaxPool2d(2) \n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(32 * 3 * 3, 10)\n",
    "    def forward(self,x):\n",
    "        x=self.ConvLayers(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=NeuralNetwork()\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3884,  0.0463, -0.0380, -0.1168, -0.0504,  0.1310,  0.3993, -0.1170,\n",
      "          0.1477,  0.3052],\n",
      "        [-0.3210, -0.0712,  0.3581,  0.0886, -0.2820,  0.2099,  0.3968, -0.0753,\n",
      "         -0.1469,  0.4600],\n",
      "        [-0.3025, -0.1474,  0.0893,  0.0085, -0.1952, -0.0548,  0.2527,  0.0852,\n",
      "         -0.0315,  0.1013],\n",
      "        [-0.3467,  0.0729,  0.1705, -0.0508, -0.1989,  0.0984,  0.2953,  0.1108,\n",
      "         -0.0103,  0.1412],\n",
      "        [-0.7932, -0.0979,  0.1578,  0.1915, -0.3488,  0.1880,  0.2216, -0.2032,\n",
      "          0.1692,  0.2568],\n",
      "        [-0.0941,  0.0575,  0.2720,  0.0532, -0.5110,  0.3188,  0.3148, -0.0984,\n",
      "         -0.2096,  0.0330],\n",
      "        [-0.3655,  0.1664, -0.0539, -0.0422, -0.0788, -0.0520,  0.4758, -0.2230,\n",
      "          0.0671,  0.2231],\n",
      "        [-0.0488, -0.1829,  0.2816,  0.0544, -0.2412,  0.5397,  0.1290, -0.1385,\n",
      "          0.1338,  0.3293],\n",
      "        [-0.1563,  0.1025,  0.3499,  0.0747, -0.2438,  0.1005,  0.1545,  0.0626,\n",
      "         -0.0955,  0.0632],\n",
      "        [-0.2416,  0.0060,  0.2403, -0.1552, -0.0190, -0.2754,  0.1335, -0.4080,\n",
      "          0.2205,  0.1035],\n",
      "        [-0.4098,  0.0757,  0.1463, -0.0870, -0.0980,  0.0905,  0.4416, -0.1961,\n",
      "         -0.1766,  0.4020],\n",
      "        [-0.2673, -0.1598,  0.3208, -0.0129, -0.3262,  0.0058,  0.3649, -0.0643,\n",
      "         -0.1696,  0.3576],\n",
      "        [-0.3062,  0.0367, -0.0305, -0.0275, -0.3378,  0.0183,  0.3755,  0.1351,\n",
      "          0.2428,  0.2014],\n",
      "        [-0.3443, -0.0451,  0.1071,  0.0873, -0.2825,  0.0769,  0.2606, -0.1520,\n",
      "          0.1134,  0.1108],\n",
      "        [-0.2882, -0.0897,  0.1124,  0.0550, -0.3501,  0.1933,  0.2202, -0.0903,\n",
      "          0.2383,  0.1536],\n",
      "        [-0.4105, -0.1672,  0.0154, -0.2362, -0.1996,  0.1504,  0.2379,  0.0325,\n",
      "          0.1269,  0.3322],\n",
      "        [-0.2803, -0.0246, -0.0028, -0.0359, -0.1663, -0.1551,  0.6085,  0.0053,\n",
      "          0.0707,  0.2250],\n",
      "        [-0.4517, -0.0544,  0.1599,  0.2296, -0.3295,  0.2494,  0.2339, -0.3472,\n",
      "         -0.3872,  0.4214],\n",
      "        [-0.2300, -0.0794, -0.0636, -0.1415, -0.2775, -0.0864,  0.2486, -0.1777,\n",
      "          0.1168,  0.5528],\n",
      "        [-0.2526, -0.0427,  0.1383,  0.0356, -0.1291,  0.2477,  0.1969,  0.0714,\n",
      "          0.1195,  0.2328],\n",
      "        [-0.5098,  0.0543,  0.0081, -0.0734, -0.4396, -0.2451,  0.5005, -0.2238,\n",
      "         -0.2178, -0.0135],\n",
      "        [-0.4834, -0.0253,  0.4404,  0.0773, -0.4003,  0.0989,  0.5887,  0.1353,\n",
      "          0.2191,  0.0423],\n",
      "        [-0.4754,  0.0072,  0.1481,  0.0787, -0.2067, -0.1131,  0.3135,  0.0253,\n",
      "          0.0091,  0.3094],\n",
      "        [-0.2926, -0.0085,  0.0659, -0.0964, -0.1949,  0.1406,  0.1341, -0.3957,\n",
      "          0.0189,  0.3644],\n",
      "        [-0.3133, -0.1178,  0.1504, -0.1640, -0.1186,  0.5048,  0.4781, -0.0744,\n",
      "          0.2579,  0.2862],\n",
      "        [-0.2479, -0.0875,  0.1564,  0.1198, -0.3239, -0.0340,  0.1896, -0.1135,\n",
      "         -0.0225,  0.0595],\n",
      "        [-0.4393,  0.0861,  0.1795, -0.0596, -0.2681,  0.1046,  0.1981, -0.4315,\n",
      "          0.0130,  0.4565],\n",
      "        [-0.5195,  0.0248,  0.0136,  0.1290, -0.0342,  0.3413,  0.7056, -0.3012,\n",
      "          0.0790,  0.4288],\n",
      "        [-0.2965, -0.1161, -0.0930,  0.1519, -0.1335,  0.1927,  0.3368, -0.1495,\n",
      "          0.1659,  0.4564],\n",
      "        [-0.3418, -0.1421,  0.0454, -0.0879, -0.1365,  0.2179,  0.2474, -0.3060,\n",
      "          0.2393,  0.2866],\n",
      "        [-0.1193, -0.0616,  0.1538,  0.1347, -0.2841,  0.1320, -0.0058, -0.1153,\n",
      "          0.1771,  0.1563],\n",
      "        [-0.2989,  0.0449, -0.0226,  0.1894, -0.2887, -0.1428,  0.2182,  0.1948,\n",
      "          0.0894,  0.1796]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for batch,(X,y) in enumerate(train_dataloader):\n",
    "    print(model(X))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "def train(train_dataloader,test_dataloader, model, loss_fn, optimizer):\n",
    "    size_train = len(train_dataloader.dataset)\n",
    "    size_test = len(test_dataloader.dataset)\n",
    "    correct_train=0\n",
    "    train_loss=0\n",
    "    correct_test=0\n",
    "    test_loss=0\n",
    "    num_batches_test = len(test_dataloader)\n",
    "    num_batches_train = len(train_dataloader)\n",
    "    for batch_no,(X,y) in enumerate(train_dataloader):\n",
    "        X,y = X.to(device),y.to(device)\n",
    "        pred = model(X)\n",
    "        loss=loss_fn(pred,y)\n",
    "        train_loss += loss_fn(pred, y).item()\n",
    "        correct_train += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct_test += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    print(f\"Train Error: Accuracy: {(correct_train/(size_train)):>0.3f} loss: {train_loss/num_batches_train:>7f} \")\n",
    "    print(f\"Test Error: Accuracy: {(100*(correct_test/size_test)):>0.3f}%, loss: {(test_loss/num_batches_test):>8f} \\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.883 loss: 0.319249 \n",
      "Test Error: Accuracy: 87.570%, loss: 0.355972 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.885 loss: 0.318302 \n",
      "Test Error: Accuracy: 86.900%, loss: 0.368445 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.884 loss: 0.316272 \n",
      "Test Error: Accuracy: 87.310%, loss: 0.353643 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.884 loss: 0.317357 \n",
      "Test Error: Accuracy: 87.050%, loss: 0.358617 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.884 loss: 0.315426 \n",
      "Test Error: Accuracy: 86.840%, loss: 0.370116 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.885 loss: 0.311697 \n",
      "Test Error: Accuracy: 87.000%, loss: 0.369441 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.885 loss: 0.313189 \n",
      "Test Error: Accuracy: 87.230%, loss: 0.356453 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.886 loss: 0.311477 \n",
      "Test Error: Accuracy: 87.210%, loss: 0.360286 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.884 loss: 0.313730 \n",
      "Test Error: Accuracy: 86.820%, loss: 0.367464 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.885 loss: 0.311350 \n",
      "Test Error: Accuracy: 87.420%, loss: 0.357966 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.885 loss: 0.311533 \n",
      "Test Error: Accuracy: 87.150%, loss: 0.366413 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.887 loss: 0.310245 \n",
      "Test Error: Accuracy: 87.200%, loss: 0.361771 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.886 loss: 0.309937 \n",
      "Test Error: Accuracy: 86.830%, loss: 0.371709 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.886 loss: 0.310440 \n",
      "Test Error: Accuracy: 87.470%, loss: 0.350083 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.886 loss: 0.309322 \n",
      "Test Error: Accuracy: 87.220%, loss: 0.367408 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.885 loss: 0.309305 \n",
      "Test Error: Accuracy: 87.380%, loss: 0.357458 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.886 loss: 0.310873 \n",
      "Test Error: Accuracy: 87.850%, loss: 0.355719 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.888 loss: 0.308251 \n",
      "Test Error: Accuracy: 87.860%, loss: 0.345230 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.887 loss: 0.306288 \n",
      "Test Error: Accuracy: 87.560%, loss: 0.351115 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.887 loss: 0.309026 \n",
      "Test Error: Accuracy: 87.300%, loss: 0.363419 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.888 loss: 0.306215 \n",
      "Test Error: Accuracy: 87.690%, loss: 0.356987 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.888 loss: 0.306463 \n",
      "Test Error: Accuracy: 87.490%, loss: 0.346814 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.888 loss: 0.304000 \n",
      "Test Error: Accuracy: 87.260%, loss: 0.362487 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.889 loss: 0.303868 \n",
      "Test Error: Accuracy: 87.810%, loss: 0.342787 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.887 loss: 0.306440 \n",
      "Test Error: Accuracy: 87.050%, loss: 0.361065 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.886 loss: 0.308465 \n",
      "Test Error: Accuracy: 87.420%, loss: 0.355271 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.888 loss: 0.307854 \n",
      "Test Error: Accuracy: 87.560%, loss: 0.353497 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.887 loss: 0.303533 \n",
      "Test Error: Accuracy: 87.440%, loss: 0.346997 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.888 loss: 0.305806 \n",
      "Test Error: Accuracy: 87.340%, loss: 0.355471 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "Train Error: Accuracy: 0.888 loss: 0.303982 \n",
      "Test Error: Accuracy: 87.130%, loss: 0.354094 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader,test_dataloader, model, loss_fn, optimizer)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
